##Overview
This test assesses fundamental knowledge of statistics and probability. 

##Instructions
Please use either R or Python to complete this test. Your answers must be presented in a markdown (.md) file that is formatted for 
HTML output.

Answer every question to the best of your ability, and if you don't know the answer, please describe and articulate why. As with most tests, your problem solving method and approach is 
just as important than the end result.

If you need more clarity for any question, please email hello@brooklyndatascience.com. 

Again, please commit your work as you progress through the exercises. 

##Questions

1. The height (cm) of six random people in Williamsburg is sampled as the following: 178, 163, 168, 167, 170, 150
	
a. Calculate the Five Number Summary: Min, First Quartile (Q1), Sample Median, Third Quartile (Q2), Maximum
```{r}
min(178, 163, 168, 167, 170, 150)
quantile(c(178, 163, 168, 167, 170, 150))
```
The minimum is 150.
The Q1 is 164.0.
The Q2 is 169.5.

b. Calculate the Sample Mean
```{r}
mean(178, 163, 168, 167, 170, 150)
```
The sample mean is 178.

c. Calculate the Interquartile Range (IQR)
```{r}
IQR(c(178, 163, 168, 167, 170, 150))
169.5 - 164.0
```
The IQR is 5.5.

d. Which, if any, of the observations are possible outliers?
```{r}
boxplot(c(178, 163, 168, 167, 170, 150))
```

The number 150 is a possible outlier, as the boxplot indicates.

e. Create a boxplot of the observations
See above.

f. Calculate the sample variance and sample standard deviation
```{r}
var(c(178, 163, 168, 167, 170, 150))
sd(c(178, 163, 168, 167, 170, 150))
```
The sample variance is 86.
The sample standard deviation is 9.3.

2. Group the following data types as either Metric, Non-Metric, or Inbetween (Metric implies we can calculate a "distance" between any two random observations),
and categorize each one as either Continuous, Nominal/Categorical, Ordinal, or Interval/Discrete.
	
i. All real numbers 
Metric
Continuous
	
ii. {First Place, Second Place, Third Place}
Inbetween.
Their distance can be simply calculated as 1. But depending on the context, the distance could be different. For example, in a weightlifting race, the athlete in the first place lifts 160kg, the second place lifts 150kg, the third place 120kg. Then the distances between first and second, second and third are different.
	
Ordinal
	
iii. {Green, Blue, Yellow, Brown}
Non-metric
Discrete
	
iv. Five point scale: 1, 2, 3, 4, 5
Metric
Ordinal
	
v. Ranking of attitudes on a 5 point scale: strongly disagree to strongly agree
Metric
Ordinal
	
3. What is the "68, 95, 99.7" rule for the Normal distribution?
The 68–95–99.7 represent the percentage of values that lie within a band around the mean in a normal distribution with a width of one, two and three standard deviations

4. IQ tests are standardized to follow an approximately normal distribution with a mean of 100 and a standard deviation of 16. (i.e., data is N(100 , 16) ). 
	
a. What percentile is an IQ of 116?
```{r}
pnorm(116, mean = 100, sd = 16)
```
84.13%
	
b. Approximately what percent of people will have an IQ score of 90 or less? What is the z-score?
```{r}
pnorm(90, mean = 100, sd = 16)
```
26.6%.
```{r}
(90 - 100) / 16
```
-0.625

5. There are three cabinets, A, B, and C, each of which has two drawers. Each drawer contains one coin; 
A has two gold coins, B has two silver coins, and C has one gold and one silver coin. A cabinet is chosen at random, 
one drawer is opened, and a silver coin is found. What is the probability that the other drawer in that cabinet contains a silver coin?

0.5. Since a silver coin is found, the cabinate chosen has to be B or C. The other drawer in B has a silver coin, the other drawer in C has a gold coin. So the probability that the other drawer in that cabinate contains a silver coin is 1/2.

6. A line segment of length 1 is cut once at random. What is the probability that the longer piece is more than twice 
the length of the shorter piece?
1/3. Suppose the lengths of the two pieces are a and b respectively. Without loss of generalization, suppose a is the longer one. Then a follows uniform(0, 1) distribution. When a >= 2b, a >= 2(1 - a), then we have a >= 2/3. The probability of a >= 2/3 is 1/3.

7. 10% of the adult population in Brooklyn has the flu virus. Tests are being given at Duane Reade, and the test has 
a false positive rate of 1% and a false negative rate of .03%. Given that a person has a positive test result, 
what is the conditional probability that this person indeed has the flu virus. 
According to Bayes Theorem:
p(flu | positive) = p(positive | flu) * p(flu) / p(positive | flu) * p(flu) + p(positive | non-flu) * p(non-flu) = 99% * 10% / (99% * 10% + 1% * 90%) = 91.77%

8. On average, a water treatment facility has a critical component failure 2 times per year, Assuming the failures 
follow a Poisson distribution with mean mu = 2 years, What is the probability of having 100 or more critical failures in the next 50 years?
It seems that there is a mistake here. The mean mu should be 2 times, instead of 2 years. The failures in the next 50 years follows a Poisson(100) distribution. So the probability of having 100 or more critical failures in the next 50 years can be calculated as follows:
```{r}
1 - ppois(100, lambda = 100)
```
The probability is 0.4734.

9. A particular area in Bushwick contains 8000 new apartment units. In a survey of the occupants, a simple random sample of size 100 yields the information that the average number of umbrellas per apartment is 1.6 
with a sample standard deviation of .8. 
	
a. What is the estimated standard error of the sample mean?
```{r}
0.8 / sqrt(100)
```
0.08.

b. What is a 95% Confidence Interval for the population average?
```{r}
1.6 + 1.96 * 0.08 * c(-1, 1)
```
The 95% confidence interval is (1.4, 1.8)

c. What is an estimate for the total number of umbrellas, U?
```{r}
1.6 * 8000
```
12800 umbrellas.
	
d. What is the estimated standard error of U?
```{r}
0.8 * sqrt(8000)
```
71.55

e. What is a 95% Confidence Interval for the total number of umbrellas? 
```{r}
12800 + 1.96 * 71.55 * c(-1, 1)
```
(12660, 12940)
	
10. Use the Monte Carlo method to approximate the standard normal density on the interval [0,1]. 
Use at least 1000 randomly generated points.
```{r}
y = numeric(0)
count = 0
while (count < 1000) {
  x = rnorm(1)
  y = c(y, ifelse(x >=0 & x <= 1, 1, 0))
  if (x >= 0 & x <= 1) {count = count + 1}
}
mean(y)
```
The standard normal density on the interval [0, 1] is 0.344.

11. A particular area in Greenpoint contains 7600 residents. Robertas wants to test wheter a new promotion in this area 
will bring an increase in business. Typically, about 310 residents in the targeted area eats at Robertas each month. 
After running the promotion for one month, 350 residents from this area went to eat at Robertas. Was the promotion effective? Explain.

Assume the number of people eating at Roberts each month follows a binomial distribution. We calculate the probability that 350 or more people visit Roberts given that the binomial distribution is B(7600, 310/7600). Also set the significance level to 0.05.
```{r}
1 - pbinom(350, size = 7600, prob = 310/7600)
```
The probability is 0.01. So given a significance level of 0.05, there is a significant improvement.

12. Blue Bottle Coffee tested two new brewing methods, A and B, on a batch of single-orign beans to see which one, if any, produces the most caffeine.
Method A was tested 13 times and Method B was tested 8 times. The following table gives the measured amount of caffeine (mg) 
in an 8oz cup of coffee produced under each method. Assuming all observations are independent and the amount of caffeine produced by each method follows a normal distribution, how confident are you that the results between the two methods differ?

	Method A | Method B
------------ | -------------
79.98 | 80.02
80.04 | 79.94
80.02 | 79.98 
80.04 | 79.97
80.03 | 79.97 
80.03 | 80.03
80.04 | 79.95 
79.97 | 79.97 
80.05 | 
80.03 | 
80.02 | 
80.00 | 
80.02 |

Two-sample t-test should be used here. Set the significance level to be 0.05.
```{r}
method1 = c(79.98, 80.04, 80.02, 80.04, 80.03, 80.03, 80.04, 79.97, 80.05, 80.03, 80.02, 80.00, 80.02)
method2 = c(80.02, 79.94, 79.98, 79.97, 79.97, 80.03, 79.95, 79.97)
t.test(method1, method2, alternative = 'two.sided')
```
The p-value is 0.006939, smaller than the significance level 0.05. I am (1 - 0.0006939 = 99.93%) confident that there is significant difference between the two methods.

13. The following table gives the number of Airbnb guests staying in a Park Slope neighborhood for each month during 2014. 
Is there a seasonal pattern to when guests stay here? That is, are guest bookings uniformly distributed?

  Month | Bookings
------------ | -------------
Jan | 1668
Feb | 1407 
Mar | 1370 
Apr | 1309
May | 1341 
June | 1338
July | 1406 
Aug | 1446 
Sept | 1332
Oct | 1363
Nov | 1410 
Dec | 1526

First, create a time series object to see if there is a pattern.
```{r}
bookings = ts(c(1668, 1407, 1370, 1309, 1341, 1338, 1406, 1446, 1332, 1363, 1410, 1526), start = 1, end = 12)
plot(bookings)
```

Looks like there is no pattern. To formally test if the autocorrelation is different from zero, Ljung-Box Test is used here. 
```{r}
Box.test(bookings)
```
The p-value is 0.6144, so the autocorrelation is zero. In another word, the samples of different months can be regarded as independent samples. Then use Bartlett test to test if the variance of the seasons are homogeneous.
```{r}
seasons <- c(1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4)
bookings.df <- data.frame(bookings, seasons = as.factor(seasons))
bartlett.test(bookings, seasons, data = bookings.df)
```
The p-value is bigger than 0.05, so the variences can be argued to be the same. Now perform ANOVA.
```{r}
fit = lm(bookings ~ seasons)
anova(fit)
```
Since p-value > 0.05, we accept the null hypothesis that the means of the four seasons are equal.

14. 12 observations on 2 variables X1 and X2 were made.

  X1 | X2
------------ | -------------
16 | 8
12 | 10
13 | 6
11 | 2
10 | 8
9 | -1
8 | 4
7 | 6
5 | -3
3 | -1
2 | -3
0 | 0
	
a. What is the correlation of X1 and X2? Does this seem high enough to warrant Principal Components Analysis (PCA)?
```{r}
x1 = c(16, 12, 13, 11, 10, 9, 8, 7, 5, 3, 2, 0)
x2 = c(8, 10, 6, 2, 8, -1, 4, 6, -3, -1, -3, 0)
cor(x1, x2)
```
The correlation is 0.7456. Seems high enough to warrant PCA.

b. If you believe we should implement PCA, calculate the eigenvectors of the covariance matrix associated with X1 and X2?
```{r}
x = cbind(x1, x2)
eigen(var(x))
```
The eigenvectors are (-0.7282, -0.6853) and (0.6853, -0.7282).

c. What is the variance of the principle components?
The variance of the principle components are 38.58 and 5.606.

d. How much of the overall variability is explained by a single principal component?
```{r}
38.58 / (38.58 + 5.606)
```
There is 87.31% of the overall variability explained by a single principal component.
